{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ğŸš€ Install necessary packages\n",
        "!pip install streamlit openai h2o pandas scikit-learn pyngrok --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPwwFTjfF9T7",
        "outputId": "8c93de31-8d98-4e7a-835a-e68eca39f6f9"
      },
      "id": "BPwwFTjfF9T7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m265.9/265.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install h2o openai pandas scikit-learn"
      ],
      "metadata": {
        "id": "ASX1uw3jGNMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52fbccd-a05b-44f9-f3e1-f0efef73fe0e"
      },
      "id": "ASX1uw3jGNMB",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h2o in /usr/local/lib/python3.11/dist-packages (3.46.0.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from h2o) (2.32.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZKF4l52F-ck",
        "outputId": "785b582e-9be6-4980-c2b0-7a5f9107bb2b"
      },
      "id": "bZKF4l52F-ck",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.76.2\n",
            "    Uninstalling openai-1.76.2:\n",
            "      Successfully uninstalled openai-1.76.2\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ğŸ” Configure your API keys\n",
        "from pyngrok import ngrok, conf\n",
        "import os, time, json\n",
        "conf.get_default().auth_token = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"  # Replace with your ngrok token\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"    # Replace with your OpenAI API key"
      ],
      "metadata": {
        "id": "L3VBKebyGDCG"
      },
      "id": "L3VBKebyGDCG",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvXdFKf3W_IT"
      },
      "source": [
        "# ğŸ› ï¸ Create enhanced Streamlit app with model download, Auto-Correction + Meta Monitor\n",
        "with open(\"streamlit_app.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import os\n",
        "import time\n",
        "import streamlit as st\n",
        "import openai\n",
        "import h2o\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from h2o.automl import H2OAutoML\n",
        "\n",
        "os.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'\n",
        "os.environ['STREAMLIT_SERVER_PORT'] = '8501'\n",
        "os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'\n",
        "\n",
        "h2o.init()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "log_file = \"/content/meta_monitor.json\"\n",
        "if not os.path.exists(log_file):\n",
        "    with open(log_file, \"w\") as f:\n",
        "        json.dump({\"runs\": []}, f)\n",
        "\n",
        "st.title(\"ğŸ­ Factory AI Resilience Engine\")\n",
        "uploaded_file = st.file_uploader(\"ğŸ’¾ Upload CSV\", type=\"csv\")\n",
        "\n",
        "if uploaded_file:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.success(\"âœ… Data uploaded!\")\n",
        "    st.dataframe(df.head())\n",
        "\n",
        "    target_column = st.selectbox(\"ğŸ¯ Select Target Column\", options=df.columns, index=len(df.columns)-1)\n",
        "    drop_cols = [col for col in df.columns if col.lower() in ['udi', 'product id', 'id']]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    for col in df.select_dtypes(include='object').columns:\n",
        "        df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "    description = st.text_area(\"ğŸ“‹ Describe the disruption/problem:\")\n",
        "    run_button = st.button(\"ğŸš€ Run AI Workflow\")\n",
        "else:\n",
        "    run_button = False\n",
        "\n",
        "if run_button:\n",
        "    max_retries = 2\n",
        "    accuracy_threshold = 0.95\n",
        "    auc_threshold = 0.95\n",
        "    retry_count = 0\n",
        "    success = False\n",
        "\n",
        "    while retry_count <= max_retries and not success:\n",
        "        st.markdown(f\"### ğŸ” Attempt {retry_count + 1}\")\n",
        "        prompt = f\"\"\"\n",
        "        You are a manufacturing AI strategist.\n",
        "        Given the following problem, reason step-by-step:\n",
        "        - Root cause\n",
        "        - Recovery strategies\n",
        "        - AI tasks needed (classification/regression/forecasting)\n",
        "        - Model architecture suggestions\n",
        "\n",
        "        Problem:\n",
        "        {description}\n",
        "        \"\"\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"system\", \"content\": \"You are an AI strategist for manufacturing.\"},\n",
        "                      {\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.4,\n",
        "            max_tokens=800\n",
        "        )\n",
        "        llm_output = response['choices'][0]['message']['content']\n",
        "        st.code(llm_output)\n",
        "\n",
        "        def detect_model_type(text):\n",
        "            t = text.lower()\n",
        "            return \"classification\" if \"classification\" in t else \"regression\" if \"regression\" in t else None\n",
        "\n",
        "        task = detect_model_type(llm_output)\n",
        "        if not task:\n",
        "            st.warning(\"âš ï¸ Could not detect model type from LLM output.\")\n",
        "            break\n",
        "\n",
        "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "        train_h2o = h2o.H2OFrame(train_df)\n",
        "        test_h2o = h2o.H2OFrame(test_df)\n",
        "        x = [col for col in train_h2o.columns if col != target_column]\n",
        "        y = target_column\n",
        "        train_h2o[y] = train_h2o[y].asfactor()\n",
        "        test_h2o[y] = test_h2o[y].asfactor()\n",
        "\n",
        "        aml = H2OAutoML(max_models=10, seed=1)\n",
        "        aml.train(x=x, y=y, training_frame=train_h2o)\n",
        "        perf = aml.leader.model_performance(test_data=test_h2o)\n",
        "\n",
        "        try:\n",
        "            acc = perf.accuracy()[0][1] if task == \"classification\" else None\n",
        "            auc = perf.auc() if task == \"classification\" else None\n",
        "        except:\n",
        "            acc = auc = None\n",
        "\n",
        "        st.success(\"âœ… AutoML complete\")\n",
        "        st.text(perf)\n",
        "\n",
        "        if acc and acc >= accuracy_threshold and auc and auc >= auc_threshold:\n",
        "            success = True\n",
        "            st.success(f\"ğŸ‰ Model passed thresholds (Accuracy: {acc:.3f}, AUC: {auc:.3f})\")\n",
        "        else:\n",
        "            st.warning(f\"ğŸ” Model failed (Accuracy: {acc}, AUC: {auc}). Re-prompting LLM...\")\n",
        "            retry_count += 1\n",
        "\n",
        "    # Save meta-monitor log\n",
        "    with open(log_file, \"r\") as f:\n",
        "        logs = json.load(f)\n",
        "    logs[\"runs\"].append({\n",
        "        \"attempt\": retry_count,\n",
        "        \"success\": success,\n",
        "        \"accuracy\": acc,\n",
        "        \"auc\": auc,\n",
        "        \"timestamp\": time.time()\n",
        "    })\n",
        "    with open(log_file, \"w\") as f:\n",
        "        json.dump(logs, f, indent=2)\n",
        "\n",
        "    try:\n",
        "        varimp = aml.leader.varimp(use_pandas=True)\n",
        "        if varimp is not None and not varimp.empty:\n",
        "            st.subheader(\"ğŸ” Feature Importance\")\n",
        "            st.bar_chart(varimp.head(10).set_index(\"variable\")[\"relative_importance\"])\n",
        "        else:\n",
        "            st.info(\"â„¹ï¸ Feature importance not available.\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"âš ï¸ Could not extract feature importance: {e}\")\n",
        "\n",
        "    # ğŸ’¾ Save & offer model download\n",
        "    try:\n",
        "        model_path = h2o.save_model(model=aml.leader, path=\"/content\", force=True)\n",
        "        st.success(\"ğŸ’¾ Best model saved.\")\n",
        "        with open(model_path, \"rb\") as f:\n",
        "            st.download_button(\"ğŸ“¥ Download Trained Model\", f, file_name=os.path.basename(model_path))\n",
        "    except Exception as e:\n",
        "        st.warning(f\"âš ï¸ Model export failed: {e}\")\n",
        "''')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [],
      "id": "IvXdFKf3W_IT"
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Launch Streamlit + Ngrok\n",
        "!pkill streamlit\n",
        "os.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'\n",
        "os.environ['STREAMLIT_SERVER_PORT'] = '8501'\n",
        "os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'\n",
        "get_ipython().system_raw(\"streamlit run streamlit_app.py &\")\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"ğŸ”— Your enhanced AI Streamlit app is running at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ptElc9GldE",
        "outputId": "0bf6ab65-1644-4a39-b911-018942692f6a"
      },
      "id": "84ptElc9GldE",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”— Your enhanced AI Streamlit app is running at: NgrokTunnel: \"https://68fc-35-245-248-81.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtnD8alHW_IW"
      },
      "source": [
        "# Launch the app via ngrok!pip install pyngrok streamlit openai h2o pandas scikit-learn --quietimport os, timefrom pyngrok import ngrok, confconf.get_default().auth_token = \"YOUR_NGROK_AUTH_TOKEN\"!pkill streamlitos.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'os.environ['STREAMLIT_SERVER_PORT'] = '8501'os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'os.system(\"streamlit run streamlit_app.py &\")time.sleep(5)public_url = ngrok.connect(8501)print(f\"ğŸ”— App is live at: {public_url}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "wtnD8alHW_IW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}